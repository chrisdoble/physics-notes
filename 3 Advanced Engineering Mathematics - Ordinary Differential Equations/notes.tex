\documentclass{article}
\usepackage{amsmath} % For align*
\usepackage{enumitem} % For customisable list labels
\usepackage{graphicx} % For images
\usepackage{siunitx} % For units
\graphicspath{{./images/}}

\DeclareMathOperator{\erf}{erf}
\DeclareMathOperator{\erfc}{erfc}

\title{Advanced Engineering Mathematics Ordinary Differential Equations Notes}
\author{Chris Doble}
\date{February 2022}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction to Differential Equations}

\subsection{Definitions and Terminology}

\begin{itemize}
  \item An equation containing the derivatives of one or more dependent variables, with respect to one or more independent variables, is said to be a \textbf{differential equation} (DE)

  \item An \textbf{ordinary DE} (ODE) is a DE that contains only ordinary (i.e. non-partial) derivatives of one or more functions with respect to a single independent variable

  \item A \textbf{partial DE} is a DE that contains only partial derivatives of one or more functions of two or more independent variables

  \item The \textbf{order} of a DE is the order of the highest derivative in the equation

  \item First order ODEs are sometimes written in the \textbf{differential form} \[M(x, y) \,dx + N(x, y) \,dy = 0\]

  \item $n$-th order ODEs in one dependent variable can be expressed by the \textbf{general form} \[F(x, y, y', \ldots, y^{(n)}) = 0\]

  \item It's possible to solve ODEs in the general form uniquely for the highest derivative $y^{(n)}$ in terms of the other $n + 1$ variables, allowing them to be expressed in the \textbf{normal form} \[\frac{d^n y}{d x^n} = f(x, y, y', \ldots, y^{(n - 1)})\]

  \item An $n$-th order ODE is said be \textbf{linear} in the variable $y$ if it can be expressed in the form \[a_n(x) y^{(n)} + a_{n-1}(x) y^{(n - 1)} + \cdots + a_1(x) y' + a_0(x) y - g(x) = 0\] i.e. the dependent variable $y$ and all of its derivatives aren't raised to a power or used in nonlinear functions like $e^y$ or $\sin y$, and the coefficients $a_0$, $a_1$, $\ldots$, $a_n$ depend at most on the independent variable $x$

  \item A \textbf{nonlinear} ODE is one that is not linear

  \item A \textbf{solution} to an ODE is a function $\phi$, defined on an interval $I$ and possessing at least $n$ derivatives that are continuous on $I$, such that \[F(x, \phi(x), \phi'(x), \ldots, \phi^{n}(x)) = 0 \text{ for all } x \text{ in } I.\]

  \item The \textbf{interval of definition}, \textbf{interval of validity}, or the \textbf{domain} of a solution is the interval over which the solution is valid

  \item A solution of a DE that is $0$ on an interval $I$ is said to be a \textbf{trivial solution}

  \item Because solutions to DEs must be differentiable over their interval of validity, discontinuities, etc. must be excluded from the interval

  \item An \textbf{explicit solution} to an ODE is one where the dependent variable is expressed solely in terms of the independent variable and constants

  \item An \textbf{implicit solution} to an ODE is a relation $G(x, y) = 0$ over an interval $I$ provided there exists at least one function $\phi$ that satisfies the relation as well as the ODE on $I$

  \item When solving a first-order ODE we usually obtain a solution containing a single arbitrary constant or parameter $c$. A solution containing an arbitrary constant represents a set of solution called a \textbf{one-parameter family of solutions}

  \item When solving an $n$-th order DE we usually obtain an \textbf{$n$-parameter family of solutions}

  \item A solution of a DE that is free from arbitrary parameters is called a \textbf{particular solution}

  \item A \textbf{singular solution} is a solution to a DE that isn't a member of a family of solutions

  \item A \textbf{system of ODEs} is two or more equations involving the derivatives of two or more unknown functions of a single independent variable. A solution of such a system is a differentiable function for each equation defined on a common interval $I$ that satisfy each equation of the system on that interval
\end{itemize}

\subsection{Initial Value Problems}

\begin{itemize}
  \item An \textbf{initial value problem} is the problem of solving a DE with some given \textbf{initial conditions}, e.g. solve \[\frac{d^n y}{dx^n} = f(x, y, y', \ldots, y^{(n - 1)})\] subject to \[y(x_0) = y_0, \,y'(x_0) = y_1, \,\ldots, \,y^{(n - 1)}(x_0) = y_{n - 1}\]

  \item The domain of $y = f(x)$ differs depending on how it's considered:

        \begin{itemize}
          \item As a function its domain is all real numbers for which it's defined

          \item As a solution of a DE its domain is a single interval over which it's defined an differentiable

          \item As a solution of an initial value problem its domain is a single interval over which it's defined, differentiable, and contains the initial conditions
        \end{itemize}

  \item An initial value problem may not have any solutions. If it does it may have multiple.

  \item First-order initial value problems of the form \[\frac{dy}{dx} = f(x, y)\] \[y(x_0) = y_0\] are guaranteed to have a unique solution over an interval $I$ containing $x_0$ if $f(x, y)$ and $\partial f / \partial y$ are continuous
\end{itemize}

\subsection{Differential Equations as Mathematical Models}

\begin{itemize}
  \item A \textbf{mathematical model} is a mathematical description of a system or phenomenon

  \item The \textbf{level of resolution} of a model determines how many variables are included in the model

  \item A simple model of the growth of a population $P$ is \[\frac{dP}{dt} = k P\] where $k > 0$

  \item A simple model of radioactive decay of an amount of substance $A$ is \[\frac{dA}{dt} = k A\] where $k < 0$

  \item Newton's empirical law of cooling/warming states that the rate of change of the temperature of a body is proportional to the difference between the temperature of the body and the temperature of the surrounding medium \[\frac{dT}{dt} = k (T - T_m)\]
\end{itemize}

\section{First-Order Differential Equations}

\subsection{Solution Curves Without a Solution}

\begin{itemize}
  \item An ODE in which the independent variable doesn't appear is said to be \textbf{autonomous}, e.g. \[\frac{d y}{d x} = f(y)\]

  \item A real number $c$ is a \textbf{critical/equilibrium/stationary point} of an autonomous DE if it is a zero of $f$

  \item If $c$ is a critial point of an autonomous DE, then $y(x) = c$ is a solution

  \item A solution of the form $y(x) = c$ is called an \textbf{equilibrium solution}

  \item We can draw several conclusions about the solutions of an autonomous DE with $n$ critical points and $n + 1$ subregions bounded by the critical points:

        \begin{itemize}
          \item If $(x_0, y_0)$ is in a subregion, it remains in that subregion for all $x$

          \item By continuity, $f(y) < 0$ or $f(y) > 0$ for all $y$ in a subregion and thus $y(x)$ can't have maximum/minimum points or oscillate

          \item If $y(x)$ is bounded above by a critical point $c_1$, it must approach $y(x) = c_1$ as $x \rightarrow -\infty$ or $x \rightarrow \infty$

          \item If $y(x)$ is bounded above and below by critical points $c_1$ and $c_2$, it must approach $y(x) = c_1$ as $x \rightarrow -\infty$ and $y(x) = c_2$ as $x \rightarrow \infty$ or vice versa

          \item If $y(x)$ is bounded below by a critical point $c_1$, it must approach $y(x) = c_1$ as $x \rightarrow -\infty$ or $x \rightarrow \infty$
        \end{itemize}
\end{itemize}

\includegraphics*{attractors-and-repellers.png}

\begin{itemize}
  \item If $y(x)$ is a solution of an autonomous differential equation $d y / d x = f(y)$, then $y_1(x) = y (x - k)$, where $k$ is a constant, is also a solution
\end{itemize}

\subsection{Separable Equations}

\begin{itemize}
  \item A first-order ODE of the form \[\frac{d y}{d x} = g(x) h(y)\] is said to be \textbf{separable} or to have \textbf{separate variables}

  \item A separable first-order ODE can be solved by dividing both sides by $h(y)$ then integrating both sides with respect to $x$

        \begin{align*}
          \frac{d y}{d x}                          & = g(x) h(y)      \\
          \frac{1}{h(y)} \frac{d y}{d x}           & = g(x)           \\
          \int \frac{1}{h(y)} \frac{d y}{d x} \,dx & = \int g(x) \,dx \\
          \int \frac{1}{h(y)} \,dy                 & = \int g(x) \,dx \\
          H(y)                                     & = G(x) + c
        \end{align*}

  \item Care should be taken when dividing by $h(y)$ as it removes constant solutions $y = r$ where $h(r) = 0$
\end{itemize}

\subsection{Linear Equations}

\begin{itemize}
  \item A first-order DE of the form \[a_1(x) \frac{d y}{d x} + a_0(x) y = g(x)\] or in standard form \[\frac{d y}{d x} + P(x) y = f(x)\] is said to be a \textbf{linear equation} in the dependent variable $y$

  \item When $g(x) = 0$ or $f(x) = 0$ the linear equation is said to be \textbf{homogeneous} and is solvable via separation of variables, otherwise it is \textbf{nonhomogeneous}

  \item The nonhomogeneous linear equation's solution is the sum of two solutions $y = y_c + y_p$ where $y_c$ is a solution of the associated homogeneous equation \[\frac{d y}{d x} + P(x) y = 0\] and $y_p$ is a particular solution of the nonhomogeneous equation

  \item Nonhomogeneous linear equations can be solved via \textbf{variation of parameters}:

        \begin{enumerate}
          \item Put it into standard form

          \item Determine the \textbf{integrating factor} $e^{\int P(x) \,d x}$

          \item Multiply by the integrating factor

          \item Recognise that the left hand side of the equation is the derivative of the product of the integrating factor and $y$

          \item Integrate both sides of the equation

          \item Solve for $y$
        \end{enumerate}

  \item The \textbf{general solution} of a DE is a family of solutions that contains all possible solutions (except singular solutions)

  \item A term $y = f(x)$ in a solution is called a \textbf{transient term} if $f(x) \rightarrow 0$ as $x \rightarrow \infty$

  \item When either $P(x)$ or $f(x)$ is a piecewise-defined function the equation is then referred to as a \textbf{piecewise-linear differential equation} that can be solved by solving each interval in isolation then choosing appropriate constants to ensure the overall solution is continuous

  \item The \textbf{error function} and \textbf{complementary error function} are defined

        \begin{align*}
          \erf x + \erfc x                                                                                                              & = 1 \\
          \left( \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} \,d t \right) + \left( \frac{2}{\sqrt{\pi}} \int_x^\infty e^{-t^2} \,dt \right) & = 1
        \end{align*}
\end{itemize}

\subsection{Exact Equations}

\begin{itemize}
  \item The \textbf{differential} of a function $z = f(x, y)$ is \[dz = \frac{\partial f}{\partial x} \,d x + \frac{\partial f}{\partial y} \, dy\]

  \item A differential expression $M(x, y) \,d x + N(x, y) \,d y$ is an \textbf{exact differential} in the region $R$ of the $xy$-plane if it corresponds to the differential of some function $f(x, y)$

  \item A first-order DE of the form \[M(x, y) \,d x + N(x, y) \,d y = 0\] is said to be an \textbf{exact equation} if the expression on the left side is an exact differential

  \item A necessary and sufficient condition that $M(x, y) \,d x + N(x, y) \,d y$ be an exact differential is \[\frac{\partial M}{\partial y} = \frac{\partial N}{\partial x}\]

  \item Exact differentials can be solved by

        \begin{enumerate}
          \item Integrating $M(x, y)$ with respect to $x$ to find an expression for $f(x, y)$

                \begin{align*}
                  \frac{\partial f}{\partial x} & = M(x, y)                   \\
                  f(x, y)                       & = \int M(x, y) \,d x + g(y)
                \end{align*}

          \item Differentiating $f(x, y)$ with respect to $y$ and equating it to $N(x, y)$ to find $g'(y)$

                \begin{align*}
                  \frac{\partial f}{\partial y} = N(x, y) & = \frac{\partial}{\partial y} \int M(x, y) \,d x + g'(y)   \\
                  g'(y)                                   & = N(x, y) - \frac{\partial}{\partial y} \int M(x, y) \,d x
                \end{align*}

          \item Integrating $g'(y)$ with respect to $y$ to find $g(y)$ and substituting it into $f(x, y)$

          \item Equating $f(x, y)$ with an unknown constant $c$
        \end{enumerate}

  \item $x$ and $y$ can be swapped in the steps above (i.e. you can start by integrating $N(x, y)$ with respect to $y$, etc.)

  \item A nonexact DE $M(x, y) \,d x + N(x, y) \,d y = 0$ can sometimes be transformed into an exact DE by finding an appropriate integrating factor

        \begin{itemize}
          \item If $(M_y - N_x) / N$ is a function of $x$ alone, then an integrating factor is \[\mu(x) = e^{\int \frac{M_y - N_x}{N} \,d x}\]

          \item If $(N_x - M_y) / M$ is a function of $y$ alone, then an integrating factor is \[\mu(y) = e^{\int \frac{N_x - M_y}{M} \,d y}\]
        \end{itemize}
\end{itemize}

\subsection{Solutions by Substitution}

\begin{itemize}
  \item A function $f(x, y)$ is said to be a \textbf{homogeneous function} of degree $\alpha$ if \[f(t x, t y) = t^\alpha f(x, y)\]

  \item A first-order DE of the form \[M(x, y) \,d x + N(x, y) \,d y = 0\] is said to be \textbf{homogeneous} if both $M$ and $N$ are homogeneous functions of the same degree

  \item To solve a homogeneous first-order DE:

        \begin{enumerate}
          \item Rewrite it as \[M(x, y) = x^\alpha M(1, u) \text{ and } N(x, y) = x^\alpha N(1, u) \text{ where } u = y / x\] or \[M(x, y) = y^\alpha M(v, 1) \text{ and } N(x, y) = y^\alpha N(v, 1) \text{ where } v = x / y\]

          \item Substitute $y = u x$ and $d y = u \,d x + x \,d u$ or $x = v y$ and $d x = v \,d y + y \,d v$ as appropriate

          \item Solve the resulting first-order separable DE

          \item Substitude $u = y / x$ or $v = x / y$ as appropriate
        \end{enumerate}

  \item The DE \[\frac{d y}{d x} + P(x) y = f(x) y^n\] where $n$ is any real number is called \textbf{Bernoulli's equation}

  \item For $n = 0$ and $n = 1$ Bernoulli's equation is linear

  \item To solve Bernoulli's equation for $n \ne 0$ and $n \ne 1$:

        \begin{enumerate}
          \item Substitude $y = u^{1 / (1 - n)}$ and $\frac{d y}{d x} = \frac{d}{dx} (u^{1 / (1 - n)})$

          \item Solve the resulting linear equation

          \item Substitude $u = y^{n - 1}$
        \end{enumerate}

  \item A DE of the form \[\frac{d y}{d x} = f(A x + B y + C)\] can always be reduced to an equation with separable variables by means of the substitution \[u = A x + B y + C, B \ne 0\]
\end{itemize}

\subsection{A Numerical Method}

\begin{itemize}
  \item Approximate values for points on a solution curve near an initial point can be calculated via a \textbf{linearization} of the solution curve — a straight line that has the same slope as the initial point and passes through it

  \item \textbf{Euler's method} approximates a solution curve by iteratively stepping along its linearizations \[y_{n + 1} = y_n + h f(x_n, y_n)\] where $h$ is the \textbf{step size}
\end{itemize}

\setcounter{subsection}{8}
\subsection{Modeling with Systems of First-Order DEs}

\begin{itemize}
  \item In a system of DEs \[\frac{dx}{dt} = g_1(t, x, y)\] and \[\frac{dy}{dt} = g_2(t, x, y)\] if $g_1$ and $g_2$ are linear in $x$ and $y$, i.e. \[g_1(t, x, y) = c_1 x + c_2 y + f_1(t)\] and \[g_2(t, x, y) = c_3 x + c_4 y + f_2(t)\] it is said to be a \textbf{linear system}
\end{itemize}

\section{Higher-Order Differential Equations}

\subsection{Theory of Linear Equations}

\begin{itemize}
  \item An \textbf{$n$th-order initial-value problem (IVP)} is to solve \[a_n(x) \frac{d^ny}{dx^n} + a_{n - 1}(x) \frac{d^{n - 1}y}{dx_{n - 1}} + \cdots + a_1(x) \frac{dy}{dx} + a_0(x) y = g(x)\] subject to \[y(x_0) = y_0, \,y'(x_0) = y_1, \,\ldots, \,y^{(n - 1)}(x_0) = y_{n - 1}\]

  \item If $a_n(x)$, $a_{n - 1}(x)$, $\ldots$, $a_1(x)$, $a_0(x)$, and $g(x)$ are continuous on an interval $I$ and $a_n(x) \ne 0$ for every $x$ in the interval, then then a unique solution exists for the above IVP for every $x = x_0$ within the interval

  \item An \textbf{initial value problem} is when all of the constraints are located at the same point while a \textbf{boundary value problem} is when they're at different points

  \item Boundary value problems may have many, one, or no solutions

  \item When $g(x) = 0$ the DE is said to be \textbf{homogeneous}, otherwise it's \textbf{nonhomogeneous}

  \item The symbol $D$ is called a \textbf{differential operator} because it transforms a differentiable function into another function \[Dy = \frac{dy}{dx}\]

  \item Higher-order derivatives can be expressed as \[D^n = \frac{d^ny}{dx^n}\]

  \item An \textbf{$n$th-order differential operator} is defined to be \[L = a_n(x) D^n + a_{n - 1}(x) D^{n - 1} + \cdots + a_1(x) D + a_0(x)\]

  \item As a consequence of the properties of differentiation \[D(cf(x)) = cDf(x)\] and \[D\{f(x) + g(x)\} = Df(x) + Dg(x)\]

  \item The superposition principle for homogeneous linear $n$th-order differential equation states that if $y_1$, $y_2$, $\ldots$, $y_k$ are solutions of the equation on an interval $I$ then the linear combination \[y = c_1 y_1(x) + c_2 y_2(x) + \cdots + c_k y_k(x)\] where $c_i$ are arbitrary constants is also a solution on the interval

  \item A set of functions $f_1(x)$, $f_2(x)$, $\ldots$, $f_n(x)$ is said to be \textbf{linearly dependent} on an interval $I$ if there exists constants $c_1$, $c_2$, $\ldots$, $c_n$, not all zero, such that \[c_1 f_1(x) + c_2 f_2(x) + \cdots + c_n f_n(x) = 0\] for every $x$ in the interval. Otherwise it is said to tbe \textbf{linearly independent}

  \item The \textbf{Wronskian} of a set of $n$ functions that are $n - 1$ times differentiable is defined as \[W(f_1, f_2, \ldots, f_n) = \begin{vmatrix}
            f_1           & f_2           & \cdots & f_n           \\
            f_1'          & f_2'          & \cdots & f_n'          \\
            \vdots        & \vdots        &        & \vdots        \\
            f_1^{(n - 1)} & f_2^{(n - 1)} & \cdots & f_n^{(n - 1)}
          \end{vmatrix}\]

  \item If $y_1$, $y_2$, $\ldots$, $y_n$ are $n$ solutions to a homogeneous linear $n$th-order differential equation on an interval $I$ then the set of solutions is \textbf{linearly independent} on $I$ iff $W(y_1, y_2, \ldots, y_n) \ne 0$ for every $x$ in the interval

  \item Any set of $n$ linearly independent solutions of a homogeneous linear $n$th-order differential equation on an interval $I$ is said to be a \textbf{fundamental set of solutions} on the interval

  \item If $y_1$, $y_2$, $\ldots$, $y_n$ are a fundamental set of solutions of a homogeneous linear $n$th-order DE on an interval $I$ then the \textbf{general solution} of the equation on the interval is \[y = c_1 y_1(x) + c_2 y_2(x) + \cdots + c_n y_n(x)\] where $c_i$ are arbitrary constants

  \item Another way of saying the above is that any solution on the interval can be expressed as a linear combination of the fundamental set of solutions

  \item A linear combination of a fundamental set of solutions of a homogenous linear $n$th-order DE \[y_c(x) = c_1 y_1(x) + c_2 y_2(x) + \cdots + c_n y_n(x)\] is called the \textbf{complementary function} of associated nonhomogenous DEs

  \item If $y_p$ is any particular solution to a nonhomogeneous linear $n$th-order DE on an interval $I$ and $y_1$, $y_2$, $\ldots$, $y_n$ are a fundamental set of solutions of the associated homogeneous DE on $I$, then the \textbf{general solution} of the equation on the interval is \[y = c_1 y_1(x) + c_2 y_2(x) + \cdots + c_n y_n(x) + y_p(x)\] where $c_i$ are arbitrary constants

  \item Another way of saying the above is that any solution on the interval can be expressed as $y = y_c + y_p$

  \item The superposition for nonhomogeneous linear $n$th-order differential equations states that if $y_{p_1}$, $y_{p_2}$, $\ldots$, $y_{p_k}$ are $k$ particular solutions of a nonhomogeneous lienar $n$th-order differential equation on an interval $I$ corresponding, in turn, to $k$ distinct functions $g_1$, $g_2$, $\ldots$, $g_k$, then \[y_p(x) = y_{p_1}(x) + y_{p_2}(x) + \cdots + y_{p_k}(x)\] is a particular solution of \[a_n(x) y^{(n)} + a_{n - 1}(x) y^{(n - 1)} + \cdots + a_0(x) y = g_1(x) + g_2(x) + \cdots + g_k(x)\]
\end{itemize}

\subsection{Reduction of Order}

\begin{itemize}
  \item The \textbf{reduction of order} method requires knowledge of one non-trivial solution and comprises the following steps:

        \begin{enumerate}
          \item Recognise that the ratio of two linearly independent functions isn't constant, i.e. \[u(x) = \frac{y_1(x)}{y_2(x)} \text{ or } y_2(x) = u(x) y_1(x)\]

          \item Substitute $y_2(x) = u(x) y_1(x)$ into the DE — this will result in a DE involving only $u''$ and $u'$ which can be treated as a linear first-order DE in $u' = w$

          \item Solve for $w$

          \item Substitute $w = u'$

          \item Integrate to find $u$

          \item Multiply by $y_1$ to find $y_2$
        \end{enumerate}

  \item A formula for the above on a DE in standard form \[y'' + P(x) y' + Q(x) y = 0\] is \[y_2 = y_1(x) \int \frac{e^{-\int P(x) \,dx}}{y_1^2(x)} \,dx\]
\end{itemize}

\subsection{Homogeneous Linear Equations with Constant Coefficients}

\begin{itemize}
  \item All solutions to homogenous linear DEs \[a_n y^{(n)} + a_{n - 1} y^{(n - 1)} + \cdots + a_1 y' + a_0 y = 0\] where $a_i$ are real constants and $a_n \ne 0$ are either exponential functions or constructed from exponential functions

  \item Substituting a solution $y = e^{mx}$ we find \[e^{mx} (a_n m^n + a_{n - 1} m^{n - 1} + \cdots + a_1 m + a_0) = 0\] where the term in brackets is called the \textbf{auxiliary equation} of the DE

  \item Thus, the solution $y = e^{mx}$ is valid if $m$ is a root of the auxiliary equation

  \item Real roots correspond to solutions of the form \[y = c e^{mx}\]

  \item Complex roots $\alpha \pm i \beta$ correspond to solutions of the form \[y_1 = c_1 e^{\alpha x} \cos \beta x \text{ and } y_2 = c_2 e^{\alpha x} \sin \beta x\]

  \item A root $m$ of multiplicity $k$ corresponds to the solutions \[e^{m x}, \: x e^{mx}, \: x^2 e^{mx}, \: \ldots, \: x^{k - 1} e^{mx}\]
\end{itemize}

\subsection{Undetermined Coefficients}

\begin{itemize}
  \item The \textbf{method of undetermined coefficients} may be used to find a particular solution to nonhomogenous linear differential equations where the input function is comprised of constants, polynomials, exponentials $e^{\alpha x}$, sines, and cosines

  \item To apply the method you:

        \begin{enumerate}
          \item Solve the associated homogeneous equation

          \item Assume the particular solution has the same form as the input function

          \item If a term in the proposed solution is present in the complementary function, multiply it by $x^n$ where $n$ is the smallest positive integer that removes the duplication

          \item Substitute the proposed solution into the DE

          \item Solve for the unknown constants
        \end{enumerate}
\end{itemize}

\includegraphics*[scale=0.44]{trial-particular-solutions.png}

\subsection{Variation of Parameters}

\begin{itemize}
  \item The \textbf{method of variation of parameters} can be used to find a particular solution of a nonhomogeneous linear $n$th-order DE

  \item To apply the method you:

        \begin{enumerate}
          \item Solve the homogeneous equation to find the complementary function

          \item Assume the solution has the form \[y_p = u_1(x) y_1(x) + \cdots + u_n(x) y_n(x)\] where $n$ is the order of the equation and $y_i$ are the fundamental set of solutions from the complementary equation

          \item Convert to standard form by dividing by the leading coefficient \[y^{(n)} + a_{n - 1}(x) y^{(n - 1)} + \cdots + a_1(x) y' + a_0(x) y = f(x)\]

          \item Solve the system of linear equations

                \begin{align*}
                  y_1 u_1' + \cdots + y_n u_n'                     & = 0    \\
                  y_1' u_1' + \cdots + y_n' u_n'                   & = 0    \\
                  \vdots \qquad \qquad                                      \\
                  y_1^{(n - 1)} u_1' + \cdots + y_n^{(n - 1)} y_n' & = 0    \\
                  y_1^{(n)} u_1' + \cdots + y_n^{(n)} u_n'         & = f(x)
                \end{align*}

                via Cramer's method:

                \begin{enumerate}
                  \item Compute the Wronskian of $y_i$ \[W = \begin{vmatrix}
                            y_1       & \cdots & y_n       \\
                            y_1'      & \cdots & y_n'      \\
                            \vdots    & \ddots & \vdots    \\
                            y_1^{(n)} & \cdots & y_n^{(n)}
                          \end{vmatrix}\]

                  \item Compute $u_i'$ for $i = 1, \: \ldots, \: n$ where \[u_i' = \frac{W_i}{W}\] and $W_i$ is the determinant of the matrix formed by replacing the $i$th column of the Wronskian matrix with the column vector \[\begin{bmatrix}
                            0      \\
                            \vdots \\
                            0      \\
                            f(x)
                          \end{bmatrix}\]
                \end{enumerate}

          \item Integrate each $u_i'$ to find $u_i$
        \end{enumerate}
\end{itemize}

\subsection{Cauchy-Euler Equations}

\begin{itemize}
  \item A \textbf{Cauchy-Euler equation} is a linear differential equation of the form \[a_n x^n \frac{d^n y}{dx^n} + a_{n - 1} x^{n - 1} \frac{d^{n - 1} y}{dx^{n - 1}} + \cdots + a_1 x \frac{dy}{dx} + a_0 y = g(x)\]

  \item To solve a homogeneous Cauchy-Euler equation you:

        \begin{enumerate}
          \item Assume the equation has a solution of the form $y = x^m$, giving

                \begin{align*}
                  a_n x^n \frac{d^n y}{dx^n} & = a_n x^n m (m - 1) (m - 2) \cdots (m - n + 1) x^{m - n} \\
                                             & = a_n m (m - 1) (m - 2) \cdots (m - n + 1) x^m
                \end{align*}

                and the equation then becomes \[f(m) x^m = 0\] where $f(m)$ is a polynomial in $m$ known as the auxiliary or characteristic equation, the roots of which form the general solution

          \item Solve the auxiliary equation where

                \begin{itemize}
                  \item A real root $m$ corresponds to a solution \[y = c x^m\]

                  \item Complex roots $\alpha \pm i \beta$ correspond to solutions \[x^\alpha (c_1 \cos (\beta \ln x) + c_2 \sin (\beta \ln x))\]

                  \item A root $m$ of multiplicity $k$ corresponds to solutions \[x^m, \: x^m \ln x, \: x^m (\ln x)^2\, \:\ldots, \: x^m (\ln x)^{k - 1}\]
                \end{itemize}
        \end{enumerate}

  \item To solve a nonhomogeneous Cauchy-Euler euqation you:

        \begin{enumerate}
          \item Solve the associated homogeneous equation

          \item Find a particular solution via variation of parameters
        \end{enumerate}
\end{itemize}

\end{document}