\documentclass{article}
\usepackage{amsmath} % For align*
\usepackage{bookmark} % For links
\usepackage{float} % For the [H] option on figures
\usepackage{graphicx} % For images

\graphicspath{{./images/}}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue
}

\newcommand{\ev}[1]{\langle #1 \rangle}

\title{Introduction to Quantum Mechanics by David J. Griffiths Notes}
\author{Chris Doble}
\date{March 2024}

\begin{document}

\maketitle

\tableofcontents

\part{Theory}

\section{The Wave Function}

\subsection{The Schrödinger Equation}

\begin{itemize}
  \item The \textbf{Schrödinger equation} \[i \hbar \frac{\partial \Psi}{\partial t} = -\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi}{\partial x^2} + V \Psi\] is to quantum mechanics what Newton's second law is to classical mechanics. Given suitable initial conditions — typically $\Psi(x, 0)$ — the Schrödinger equation determines $\Psi(x, t)$ for all future time.
\end{itemize}

\subsection{The Statistical Interpretation}

\begin{itemize}
  \item The \textbf{Born rule} states that $|\Psi(x, t)|^2$ gives the probability of finding the particle at point $x$ at time $t$ or \[\int_a^b |\Psi(x, t)|^2 \,d x\] gives the probability of finding the particle between $a$ and $b$ at time $t$.

  \item This statistical interpretation introduces indeterminacy to quantum mechanics — we can't predict with certainty the particle's position.

  \item Suppose we measure a particle's position to be $C$. Where was it before we took the measurement? In the past there were three main schools of thought:

        \begin{enumerate}
          \item The \textbf{realist} position believes that the particle was at $C$ but $\Psi$ doesn't give us enough information to determine that — there's another \textbf{hidden variable} that would allow us to.

          \item The \textbf{orthodox} position (also known as the \textbf{Copenhagen interpretation}) believes that the particle didn't have a definite position but the act of measuring it forced it to do so.

          \item The \textbf{agnostic} position believes that it doesn't matter and is potentially unknowable.
        \end{enumerate}

  \item \textbf{Bell's theorem} confirms the orthodox interpretation.

  \item If we take two consecutive measurements of a particle, they will both yield the same result. The first measurement causes the wavefunction to \textbf{collapse} such that it is peaked only at the particle's measured location. If the system is allowed to evolve between the measurements the wavefunction will ``spread out'' but if done in quick succession the result won't change.
\end{itemize}

\subsection{Probability}

\subsubsection{Discrete Variables}

\begin{itemize}
\item The average value of a discrete variable $j$ is \[\ev{j} = \frac{\sum j N(j)}{N} = \sum_{j = 0}^\infty j P(j)\] where $N$ is the size of the population, $N(j)$ is the number of $j$s in the population, and $P(j)$ is the probability of randomly selecting a $j$ from the population.

  \item In quantum mechanics the average is usually the quantity of interest and it is called the \textbf{expectation value} (even though it may not be the most probable value).

\item The average value of a function $f$ of a discrete variable $j$ is \[\ev{f(j)} = \sum_{j = 0}^\infty f(j) P(j).\]

\item Two distributions could have the same median, mean, mode, and size but be spread out differently. One way to quantify this could be to calculate how far each element is from the average \[\Delta j = j - \ev{j}\] and calculate the average of $\Delta j$. However, it ends up being zero \begin{align*}
\langle \Delta j \rangle & = \sum (j - \ev{j}) P(j)         \\
& = \sum j P(j) - \ev{j} \sum P(j) \\
& = \ev{j} - \ev{j}     \\
                                   & = 0.
        \end{align*} To avoid this we calculate the average of the square of $\Delta j$ \[\sigma^2 = \langle (\Delta j)^2 \rangle\] which is known as the \textbf{variance} of the distribution.

  \item The square root of the variance is called the \textbf{standard deviation}.

  \item A useful theorem on variances is \begin{align*}
          \sigma^2 & = \langle (\Delta j)^2 \rangle                                                    \\
                   & = \sum (\Delta j)^2 P(j)                                                          \\
& = \sum (j - \ev{j})^2 P(j)                                             \\
& = \sum (j^2 - 2 j \ev{j} + \ev{j}^2) P(j)                   \\
& = \sum j^2 P(j) - 2 \ev{j} \sum j P(j) + \ev{j}^2 \sum P(j) \\
& = \ev{j^2} - 2 \ev{j}^2 + \ev{j}^2               \\
& = \ev{j^2} - \ev{j}^2
\end{align*} and thus the standard deviation can be calculated as \[\sigma = \sqrt{\ev{j^2} - \ev{j}^2}\] which is usually easier than the full formula.
\end{itemize}

\subsubsection{Continuous Variables}

\begin{itemize}
  \item The equations above translate as expected to continuous variables: \begin{align*}
          P_{a b}              & = \int_a^b \rho(x) \,d x                     \\
          1                    & = \int_{-\infty}^{+\infty} \rho(x) \,d x     \\
\ev{x}    & = \int_{-\infty}^{+\infty} x \rho(x) \,d x   \\
\ev{f(x)} & = \int{-\infty}^{+\infty} f(x) \rho(x) \,d x \\
\sigma^2             & = \ev{x^2} - \ev{x}^2
        \end{align*}
\end{itemize}

\subsection{Normalization}

\begin{itemize}
  \item In order for the statistical interpretation of the wavefunction to make sense, it must be the case that \[\int_{-\infty}^\infty |\Psi(x, t)|^2 \,d x = 1,\] i.e. the particle must be somewhere.

  \item The process of multiplying a candidate wavefunction by a complex constant $A$ to make this hold is called \textbf{normalization}.

  \item For some solutions to the Schrödinger equation, the integral is infinite in which case there is no $A$ that normalizes the wavefunction. The same goes for $\Psi = 0$. Such \textbf{non-normalizable} solutions can't represent particles so they must be rejected.

  \item But if we normalize the wavefunction at $t = 0$, how do we know it stays normalized? It turns out that the integral \[\int_{-\infty}^\infty |\Psi(x, t)|^2 \,d x\] is constant (independent of time) so if it's normalized at $t = 0$ it stays normalized.
\end{itemize}

\subsection{Momentum}

\begin{itemize}
  \item What does \[\ev{x} = \int_{-\infty}^\infty x |\Psi(x, t)|^2 \,d x\] mean? It doesn't mean that if you measure the position of a particle over and over again and take the average of the results you'll get $\int x |\Psi|^2 \,d x$. The first measurement causes the wavefunction to collapse so you'll get the same measurement each time. Instead, it means if you have a large number of particles all in the same state $\Psi$, measure the position of each of them, and take the average of the results you'll get $\int x |\Psi|^2 \,d x$.

  \item The expectation value of the velocity is equal to the time derivative of the expectation value of the position \[\ev{v} = \frac{d \ev{x}}{d t} = -\frac{i \hbar}{m} \int \Psi^* \frac{\partial \Psi}{\partial x} \,d x\] however it is customary to work with momentum $p = m v$ rather than velocity \[\ev{p} = m \frac{d \ev{x}}{d t} = -i \hbar \int \Psi^* \frac{\partial \Psi}{\partial x} \,d x.\]

  \item The above can be rewritten in the form \begin{align*}
          \ev{x} & = \int \Psi^* [x] \Psi \,d x                                                  \\
          \ev{p} & = \int \Psi^* \left[ -i \hbar \frac{\partial}{\partial x} \right] \Psi \,d x.
        \end{align*} The values in the square brackets are called \textbf{operators} and we say that the operator $x$ ``represents'' position and the operator $-i \hbar (\partial / \partial x)$ ``represents'' momentum. To calculate expectation values we place the appropriate operator between $\Psi^*$ and $\Psi$ and integrate.

  \item All other values of interest can be expressed in terms of position and momentum, e.g. kinetic energy is \[T = \frac{1}{2} m v^2 = \frac{p^2}{2 m}.\] Their operators can be determined by substituting $p = -i \hbar (\partial / \partial x)$, e.g. kinetic energy is \[-\frac{\hbar^2}{2 m} \frac{\partial^2}{\partial x^2}\] such that \[\ev{T} = -\frac{\hbar^2}{2 m} \int \Psi^* \frac{\partial^2 \Psi}{\partial x^2} \,d x.\] In general \[\ev{Q(x, p)} = \int \Psi^* \left[ Q(x, -i \hbar \partial / \partial x) \right] \Psi \,d x.\]
\end{itemize}

\subsection{The Uncertainty Principle}

\begin{itemize}
  \item If a wave is spread out (e.g. if you shake a rope up and down repeatedly), its position isn't well defined but its wavelength is. On the other hand, if a wave is localised (e.g. if you shake a rope up and down once to make a spike), its position is well defined but its wavelength isn't.

  \item The momentum of a particle is related to its wavelength by the \textbf{de Broglie formula} \[p = \frac{h}{\lambda} = \frac{2 \pi \hbar}{\lambda}.\]

  \item If a wavefunction is periodic its position isn't well defined but its wavelength is and thus so is its momentum. If a wavefunction is localised its position is well defined but its wavelength isn't and thus neither is its momentum. This is formalised by the \textbf{Hiesenberg uncertainty principle} \[\sigma_x \sigma_p \ge \frac{\hbar}{2}\] where $\sigma_x$ and $\sigma_p$ are the standard deviations in $x$ and $p$, respectively.
\end{itemize}

\section{Time-Independent Schrödinger Equation}

\subsection{Stationary States}

\begin{itemize}
  \item The Schrödinger equation \[i \hbar \frac{\partial \Psi}{\partial t} = -\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi}{\partial x^2} + V \Psi\] can be solved via separation of variables if $V$ is independent of $t$. In that case we assume $\Psi(x, t) = \psi(x) \varphi(t)$ and separation gives the two ODEs \[i \hbar \frac{1}{\varphi} \frac{d \varphi}{d t} = E\] which has no name and \[-\frac{\hbar^2}{2 m} \frac{\partial^2 \psi}{d x^2} + V \psi = E \psi\] which is called the \textbf{time-independent Schrödinger equation}. The solution to the former is \[\varphi(t) = C e^{-i E t / \hbar}\] but the constant $C$ can be absorbed into $\psi$. The latter can't be solved until $V$ is specified.

  \item While there are many solutions to the Schrödinger equation that don't have the form $\psi(x) \varphi(t)$, those that do have three interesting properties:

        \begin{enumerate}
          \item They are stationary states. The wave function has the form \[\Psi(x, t) = \psi(x) e^{-i E t / \hbar}\] so the probability density is \[|\Psi|^2 = \Psi^* \Psi = \psi^* e^{i E t / \hbar} \psi e^{-i E t / \hbar} = |\psi|^2,\] i.e. it's constant in time. Similarly, time dependence drops out of the expectation value formula so they're also constant in time.

          \item They are states of definite total energy. In classical mechanics the total energy is called the Hamiltonian \[H(x, p) = \frac{p^2}{2 m} + V(x).\] The equivalent quantum operator is \[\hat{H} = -\frac{\hbar^2}{2 m} \frac{\partial^2}{\partial x^2} + V(x)\] thus the time-independent Schrödinger equation can be written \[\hat{H} \psi = E \psi\] and the expectation value of the total energy can be written \[\ev{H} = \int \psi^* \hat{H} \psi \,d x = E \int |\psi|^2 \,d x = E \int |\Psi|^2 \,d x = E.\] Moreover, \[\hat{H}^2 \psi = \hat{H} (\hat{H} \psi) = \hat{H} (E \psi) = E (\hat{H} \psi) = E^2 \psi\] so \[\ev{H^2} = \int \psi^* \hat{H}^2 \psi \,d x = E^2 \int |\psi|^2 \,d x = E^2 \int |\Psi|^2 \,dx = E^2.\] Thus the variance of $H$ is \[\sigma_H^2 = \ev{H^2} - \ev{H}^2 = 0\] meaning every measurement of the total energy of the system will return the same value $E$.

          \item The general solution to the time-dependent Schrödinger equation is a linear combination of separable solutions. The time-independent Schrödinger equation yields an infinite number of solutions $\psi_1(x)$, $\psi_2(x)$, $\ldots$, $\psi_n(x)$ each with its associated separation constant $E_1$, $E_2$, $\ldots$, $E_n$ — one for each \textbf{allowed energy}. The general solution is then given by \[\Psi(x, t) = \sum_{n = 1}^\infty c_n \psi_n(x) e^{-i E_n t / \hbar}\] with appropriate choice of $c_n$ to fit the initial conditions.
        \end{enumerate}

  \item The general approach to solving the time-dependent Schrödinger equation with given initial conditions and potential energy function is:

        \begin{enumerate}
          \item Solve the time-independent Schrödinger equation to get an infinite set of solutions $\psi_n(x)$.

          \item Fit the linear combination of those solutions \[\Psi(x, 0) = \sum_{n = 1}^\infty c_n \psi_n(x)\] to the initial conditions.

          \item Multiply each term in the sum by its associated time dependence \[\Psi(x, t) = \sum_{n = 1}^\infty c_n \psi_n(x) e^{-i E_n t / \hbar} = \sum_{n = 1}^\infty c_n \Psi_n(x, t).\]
        \end{enumerate}

  \item The physical meaning of the constants $c_n$ is thus: $|c_n|^2$ is the probability that a measurement of the system's energy would return the value $E_n$. This means that \[\sum_{n = 1}^\infty |c_n|^2 = 1\] and \[\ev{H} = \sum_{n = 1}^\infty |c_n|^2 E_n.\] The probability of measuring any particular energy is constant in time and thus the expectation value of $H$ — this is part of energy conservation.
\end{itemize}

\end{document}