\documentclass{article}
\usepackage{amsfonts} % For mathbb
\usepackage{amsmath} % For align*
\usepackage{bookmark} % For links
\usepackage{float} % For the [H] option on figures
\usepackage{graphicx} % For images

\graphicspath{{./images/}}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue
}

\newcommand{\ev}[1]{\langle #1 \rangle}

\title{Introduction to Quantum Mechanics by David J. Griffiths Notes}
\author{Chris Doble}
\date{March 2024}

\begin{document}

\maketitle

\tableofcontents

\part{Theory}

\section{The Wave Function}

\subsection{The Schrödinger Equation}

\begin{itemize}
  \item The \textbf{Schrödinger equation} \[i \hbar \frac{\partial \Psi}{\partial t} = -\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi}{\partial x^2} + V \Psi\] is to quantum mechanics what Newton's second law is to classical mechanics. Given suitable initial conditions — typically $\Psi(x, 0)$ — the Schrödinger equation determines $\Psi(x, t)$ for all future time.
\end{itemize}

\subsection{The Statistical Interpretation}

\begin{itemize}
  \item The \textbf{Born rule} states that $|\Psi(x, t)|^2$ gives the probability of finding the particle at point $x$ at time $t$ or \[\int_a^b |\Psi(x, t)|^2 \,d x\] gives the probability of finding the particle between $a$ and $b$ at time $t$.

  \item This statistical interpretation introduces indeterminacy to quantum mechanics — we can't predict with certainty the particle's position.

  \item Suppose we measure a particle's position to be $C$. Where was it before we took the measurement? In the past there were three main schools of thought:

        \begin{enumerate}
          \item The \textbf{realist} position believes that the particle was at $C$ but $\Psi$ doesn't give us enough information to determine that — there's another \textbf{hidden variable} that would allow us to.

          \item The \textbf{orthodox} position (also known as the \textbf{Copenhagen interpretation}) believes that the particle didn't have a definite position but the act of measuring it forced it to do so.

          \item The \textbf{agnostic} position believes that it doesn't matter and is potentially unknowable.
        \end{enumerate}

  \item \textbf{Bell's theorem} confirms the orthodox interpretation.

  \item If we take two consecutive measurements of a particle, they will both yield the same result. The first measurement causes the wavefunction to \textbf{collapse} such that it is peaked only at the particle's measured location. If the system is allowed to evolve between the measurements the wavefunction will ``spread out'' but if done in quick succession the result won't change.
\end{itemize}

\subsection{Probability}

\subsubsection{Discrete Variables}

\begin{itemize}
  \item The average value of a discrete variable $j$ is \[\ev{j} = \frac{\sum j N(j)}{N} = \sum_{j = 0}^\infty j P(j)\] where $N$ is the size of the population, $N(j)$ is the number of $j$s in the population, and $P(j)$ is the probability of randomly selecting a $j$ from the population.

  \item In quantum mechanics the average is usually the quantity of interest and it is called the \textbf{expectation value} (even though it may not be the most probable value).

  \item The average value of a function $f$ of a discrete variable $j$ is \[\ev{f(j)} = \sum_{j = 0}^\infty f(j) P(j).\]

  \item Two distributions could have the same median, mean, mode, and size but be spread out differently. One way to quantify this could be to calculate how far each element is from the average \[\Delta j = j - \ev{j}\] and calculate the average of $\Delta j$. However, it ends up being zero \begin{align*}
          \langle \Delta j \rangle & = \sum (j - \ev{j}) P(j)         \\
                                   & = \sum j P(j) - \ev{j} \sum P(j) \\
                                   & = \ev{j} - \ev{j}                \\
                                   & = 0.
        \end{align*} To avoid this we calculate the average of the square of $\Delta j$ \[\sigma^2 = \langle (\Delta j)^2 \rangle\] which is known as the \textbf{variance} of the distribution.

  \item The square root of the variance is called the \textbf{standard deviation}.

  \item A useful theorem on variances is \begin{align*}
          \sigma^2 & = \langle (\Delta j)^2 \rangle                              \\
                   & = \sum (\Delta j)^2 P(j)                                    \\
                   & = \sum (j - \ev{j})^2 P(j)                                  \\
                   & = \sum (j^2 - 2 j \ev{j} + \ev{j}^2) P(j)                   \\
                   & = \sum j^2 P(j) - 2 \ev{j} \sum j P(j) + \ev{j}^2 \sum P(j) \\
                   & = \ev{j^2} - 2 \ev{j}^2 + \ev{j}^2                          \\
                   & = \ev{j^2} - \ev{j}^2
        \end{align*} and thus the standard deviation can be calculated as \[\sigma = \sqrt{\ev{j^2} - \ev{j}^2}\] which is usually easier than the full formula.
\end{itemize}

\subsubsection{Continuous Variables}

\begin{itemize}
  \item The equations above translate as expected to continuous variables: \begin{align*}
          P_{a b}   & = \int_a^b \rho(x) \,d x                     \\
          1         & = \int_{-\infty}^{+\infty} \rho(x) \,d x     \\
          \ev{x}    & = \int_{-\infty}^{+\infty} x \rho(x) \,d x   \\
          \ev{f(x)} & = \int{-\infty}^{+\infty} f(x) \rho(x) \,d x \\
          \sigma^2  & = \ev{x^2} - \ev{x}^2
        \end{align*}
\end{itemize}

\subsection{Normalization}

\begin{itemize}
  \item In order for the statistical interpretation of the wavefunction to make sense, it must be the case that \[\int_{-\infty}^\infty |\Psi(x, t)|^2 \,d x = 1,\] i.e. the particle must be somewhere.

  \item The process of multiplying a candidate wavefunction by a complex constant $A$ to make this hold is called \textbf{normalization}.

  \item For some solutions to the Schrödinger equation, the integral is infinite in which case there is no $A$ that normalizes the wavefunction. The same goes for $\Psi = 0$. Such \textbf{non-normalizable} solutions can't represent particles so they must be rejected.

  \item But if we normalize the wavefunction at $t = 0$, how do we know it stays normalized? It turns out that the integral \[\int_{-\infty}^\infty |\Psi(x, t)|^2 \,d x\] is constant (independent of time) so if it's normalized at $t = 0$ it stays normalized.
\end{itemize}

\subsection{Momentum}

\begin{itemize}
  \item What does \[\ev{x} = \int_{-\infty}^\infty x |\Psi(x, t)|^2 \,d x\] mean? It doesn't mean that if you measure the position of a particle over and over again and take the average of the results you'll get $\int x |\Psi|^2 \,d x$. The first measurement causes the wavefunction to collapse so you'll get the same measurement each time. Instead, it means if you have a large number of particles all in the same state $\Psi$, measure the position of each of them, and take the average of the results you'll get $\int x |\Psi|^2 \,d x$.

  \item The expectation value of the velocity is equal to the time derivative of the expectation value of the position \[\ev{v} = \frac{d \ev{x}}{d t} = -\frac{i \hbar}{m} \int \Psi^* \frac{\partial \Psi}{\partial x} \,d x\] however it is customary to work with momentum $p = m v$ rather than velocity \[\ev{p} = m \frac{d \ev{x}}{d t} = -i \hbar \int \Psi^* \frac{\partial \Psi}{\partial x} \,d x.\]

  \item The above can be rewritten in the form \begin{align*}
          \ev{x} & = \int \Psi^* [x] \Psi \,d x                                                  \\
          \ev{p} & = \int \Psi^* \left[ -i \hbar \frac{\partial}{\partial x} \right] \Psi \,d x.
        \end{align*} The values in the square brackets are called \textbf{operators} and we say that the operator $x$ ``represents'' position and the operator $-i \hbar (\partial / \partial x)$ ``represents'' momentum. To calculate expectation values we place the appropriate operator between $\Psi^*$ and $\Psi$ and integrate.

  \item All other values of interest can be expressed in terms of position and momentum, e.g. kinetic energy is \[T = \frac{1}{2} m v^2 = \frac{p^2}{2 m}.\] Their operators can be determined by substituting $p = -i \hbar (\partial / \partial x)$, e.g. kinetic energy is \[-\frac{\hbar^2}{2 m} \frac{\partial^2}{\partial x^2}\] such that \[\ev{T} = -\frac{\hbar^2}{2 m} \int \Psi^* \frac{\partial^2 \Psi}{\partial x^2} \,d x.\] In general \[\ev{Q(x, p)} = \int \Psi^* \left[ Q(x, -i \hbar \partial / \partial x) \right] \Psi \,d x.\]
\end{itemize}

\subsection{The Uncertainty Principle}

\begin{itemize}
  \item If a wave is spread out (e.g. if you shake a rope up and down repeatedly), its position isn't well defined but its wavelength is. On the other hand, if a wave is localised (e.g. if you shake a rope up and down once to make a spike), its position is well defined but its wavelength isn't.

  \item The momentum of a particle is related to its wavelength by the \textbf{de Broglie formula} \[p = \frac{h}{\lambda} = \frac{2 \pi \hbar}{\lambda}.\]

  \item If a wavefunction is periodic its position isn't well defined but its wavelength is and thus so is its momentum. If a wavefunction is localised its position is well defined but its wavelength isn't and thus neither is its momentum. This is formalised by the \textbf{Hiesenberg uncertainty principle} \[\sigma_x \sigma_p \ge \frac{\hbar}{2}\] where $\sigma_x$ and $\sigma_p$ are the standard deviations in $x$ and $p$, respectively.
\end{itemize}

\section{Time-Independent Schrödinger Equation}

\subsection{Stationary States}

\begin{itemize}
  \item The Schrödinger equation \[i \hbar \frac{\partial \Psi}{\partial t} = -\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi}{\partial x^2} + V \Psi\] can be solved via separation of variables if $V$ is independent of $t$. In that case we assume $\Psi(x, t) = \psi(x) \varphi(t)$ and separation gives the two ODEs \[i \hbar \frac{1}{\varphi} \frac{d \varphi}{d t} = E\] which has no name and \[-\frac{\hbar^2}{2 m} \frac{\partial^2 \psi}{d x^2} + V \psi = E \psi\] which is called the \textbf{time-independent Schrödinger equation}. The solution to the former is \[\varphi(t) = C e^{-i E t / \hbar}\] but the constant $C$ can be absorbed into $\psi$. The latter can't be solved until $V$ is specified.

  \item While there are many solutions to the Schrödinger equation that don't have the form $\psi(x) \varphi(t)$, those that do have three interesting properties:

        \begin{enumerate}
          \item They are stationary states. The wave function has the form \[\Psi(x, t) = \psi(x) e^{-i E t / \hbar}\] so the probability density is \[|\Psi|^2 = \Psi^* \Psi = \psi^* e^{i E t / \hbar} \psi e^{-i E t / \hbar} = |\psi|^2,\] i.e. it's constant in time. Similarly, time dependence drops out of the expectation value formula so they're also constant in time.

          \item They are states of definite total energy. In classical mechanics the total energy is called the Hamiltonian \[H(x, p) = \frac{p^2}{2 m} + V(x).\] The equivalent quantum operator is \[\hat{H} = -\frac{\hbar^2}{2 m} \frac{\partial^2}{\partial x^2} + V(x)\] thus the time-independent Schrödinger equation can be written \[\hat{H} \psi = E \psi\] and the expectation value of the total energy can be written \[\ev{H} = \int \psi^* \hat{H} \psi \,d x = E \int |\psi|^2 \,d x = E \int |\Psi|^2 \,d x = E.\] Moreover, \[\hat{H}^2 \psi = \hat{H} (\hat{H} \psi) = \hat{H} (E \psi) = E (\hat{H} \psi) = E^2 \psi\] so \[\ev{H^2} = \int \psi^* \hat{H}^2 \psi \,d x = E^2 \int |\psi|^2 \,d x = E^2 \int |\Psi|^2 \,dx = E^2.\] Thus the variance of $H$ is \[\sigma_H^2 = \ev{H^2} - \ev{H}^2 = 0\] meaning every measurement of the total energy of the system will return the same value $E$.

          \item The general solution to the time-dependent Schrödinger equation is a linear combination of separable solutions. The time-independent Schrödinger equation yields an infinite number of solutions $\psi_1(x)$, $\psi_2(x)$, $\ldots$, $\psi_n(x)$ each with its associated separation constant $E_1$, $E_2$, $\ldots$, $E_n$ — one for each \textbf{allowed energy}. The general solution is then given by \[\Psi(x, t) = \sum_{n = 1}^\infty c_n \psi_n(x) e^{-i E_n t / \hbar}\] with appropriate choice of $c_n$ to fit the initial conditions.
        \end{enumerate}

  \item The general approach to solving the time-dependent Schrödinger equation with given initial conditions and potential energy function is:

        \begin{enumerate}
          \item Solve the time-independent Schrödinger equation to get an infinite set of solutions $\psi_n(x)$.

          \item Fit the linear combination of those solutions \[\Psi(x, 0) = \sum_{n = 1}^\infty c_n \psi_n(x)\] to the initial conditions.

          \item Multiply each term in the sum by its associated time dependence \[\Psi(x, t) = \sum_{n = 1}^\infty c_n \psi_n(x) e^{-i E_n t / \hbar} = \sum_{n = 1}^\infty c_n \Psi_n(x, t).\]
        \end{enumerate}

  \item The physical meaning of the constants $c_n$ is thus: $|c_n|^2$ is the probability that a measurement of the system's energy would return the value $E_n$. This means that \[\sum_{n = 1}^\infty |c_n|^2 = 1\] and \[\ev{H} = \sum_{n = 1}^\infty |c_n|^2 E_n.\] The probability of measuring any particular energy is constant in time and thus the expectation value of $H$ — this is part of energy conservation.

  \item For a solution to the Schrödinger equation to be normalisable, $E$ must be real and must exceed the minimum value of $V$.
\end{itemize}

\subsection{The Infinite Square Well}

\begin{itemize}
  \item The potential of an infinite square well is \[V(x) = \begin{cases}
            0      & 0 \le x \le a    \\
            \infty & \text{otherwise}
          \end{cases}\] and thus $\Psi(x, t) = 0$ for $x$ outside $[0, a]$.

  \item Inside such a well the time-independent Schrödinger equation reads \[-\frac{\hbar^2}{2 m} \frac{d^2 \psi}{d x^2} = E \Psi\] where $E$ must be real and greater than $0$. This can be rearranged to \[\frac{d^2 \psi}{d x^2} = -k^2 \psi\] where \[k = \frac{\sqrt{2 m E}}{\hbar}.\] This has the form of a simple harmonic oscillator and has the solution \[\psi = A \sin (k x) + B \cos (k x).\] Applying the boundary condition $\psi(0) = 0$ gives $B = 0$ and thus \[\psi = A \sin (k x).\] Applying the boundary condition $\psi(a) = 0$ gives $A \sin (k a) = 0$. We must reject $A = 0$ as that would result in the non-normalisable solution $\psi = 0$, so $\sin (k a) = 0$ and thus $k a = 0, \,\pm \pi, \,\pm 2 \pi, \,\ldots$ Again, $k = 0$ results in $\psi = 0$ so it must be rejected and we're left with \[\psi = A \sin (k_n x)\] where \[k_n = \frac{n \pi}{a}, \,n \in \mathbb{Z}^+.\]

  \item From the above, the possible values of $E$ are \[E_n = \frac{\hbar^2 k_n^2}{2 m} = \frac{n^2 \pi^2 \hbar^2}{2 m a^2}, \,n \in \mathbb{Z}^+.\] In other words, unlike in classical mechanics, a quantum particle in an infinite square well can't have any energy — it must be one of these values.

  \item To determine the value of the constant $A$ above we normalise $\psi$ \[\int_0^a |A|^2 \sin^2 (k x) \,d x = |A|^2 \frac{a}{2} = 1.\] This only determines the magnitude of $A$ but the phase doesn't affect anything so we might as well pick \[A = \sqrt{\frac{2}{a}}\] and the solutions to the time-independent Schrödinger equation inside the infinite square well are \[\psi_n(x) = \sqrt{\frac{2}{a}} \sin \left( \frac{n \pi}{a} x \right).\]

  \item The solutions $\psi_n$ have some interesting properties:

        \begin{enumerate}
          \item They alternate even and odd with respect to the centre of the well.

          \item Each subsequent solution has one more node (crossing of the axis).

          \item They are mutually orthogonal, i.e. \[\int \psi_m^* \psi_n \,d x = \begin{cases}
                    0 & m \ne n \\
                    1 & m = n
                  \end{cases}.\]

          \item The are complete, in that any other function $f(x)$ can be expressed as a linear combination of them \[f(x) = \sum_{n = 1}^\infty c_n \psi_n(x) = \sqrt{\frac{2}{a}} \sum_{n = 1}^\infty c_n \sin \left( \frac{n \pi}{a} x \right)\] where \[c_n = \int \psi_n(x)^* f(x) \,d x.\]
        \end{enumerate}

  \item The stationary states of the infinite square well are thus \[\Psi_n(x, t) = \sqrt{\frac{2}{a}} \sin \left( \frac{n \pi}{a} x \right) e^{-i (n^2 \pi^2 \hbar / 2 m a^2) t}\] and the general solution to the time-dependent Schrödinger equation is \[\Psi(x, t) = \sum_{n = 1}^\infty c_n \Psi_n(x, t)\] where $c_n$ are given by \[c_n = \sqrt{\frac{2}{a}} \int_0^a \sin \left( \frac{n \pi}{a} x \right) \Psi(x, 0) \,d x.\]
\end{itemize}

\subsection{The Harmonic Oscillator}

\begin{itemize}
  \item The equation of motion for a harmonic oscillator is \[\frac{d^2 x}{d t^2} = -k x\] where $k$ is the force constant and $x$ is the displacement from equilibrium. The solution to this differential equation is \[x = A \sin (\omega t) + B \cos (\omega t)\] where $\omega = \sqrt{k / m}$ is the angular frequency of oscillation.

  \item The potential energy of a harmonic oscillator is \[V(x) = \frac{1}{2} k x^2\] which is a parabola.

  \item Any potential function can be approximated by a parabola in the neighborhood of a local minimum $x_0$ providing the amplitude is small by expanding it as a Taylor series, dropping the first term as it's constant and doesn't affect the force, dropping the second term because $V'(x_0) = 0$, keeping the third term, and dropping higher order terms.

  \item The quantum problem is to solve the Schrödinger equation for potential \[V(x) = \frac{1}{2} m \omega^2 x^2\] where $k$ has been replaced with $m \omega^2$. The first step is to solve the time-independent Schrödinger equation: \[-\frac{\hbar^2}{2 m} \frac{d^2 \psi}{d x^2} + \frac{1}{2} m \omega^2 x^2 \psi = E \psi.\] This is typically done in one of two ways: a clever algebraic technique using ladder-operators, and a more straightforward ``brute-force'' technique using power series.
\end{itemize}

\subsubsection{Algebraic Method}

\begin{itemize}
  \item We can factor the time-independent Schrödinger equation above as \[\frac{1}{2 m} \left[ -\hbar^2 \frac{d^2}{d x^2} + (m \omega x)^2 \right] \psi = \frac{1}{2 m} [\hat{p}^2 + (m \omega x)^2] = E \psi.\] As the Hamiltonian is equal to the total energy of the system, this means \[\hat{H} = \frac{1}{2 m} [\hat{p}^2 + (m \omega x)^2].\]

  \item This form invites factorisation of the form $u^2 + v^2 = (i u + v) (-i u + v)$ however $\hat{p}$ and $x$ are operators and they do not, in general, commute (i.e. $\hat{p} x \ne x \hat{p}$). We can try anyway by introducing the quantities \[\hat{a}_\pm = \frac{1}{\sqrt{2 \hbar m \omega}} (\mp i \hat{p} + m \omega x).\] Their product is \begin{align*}
          \hat{a}_- \hat{a}+ & = \frac{1}{2 \hbar m \omega} (i \hat{p} + m \omega x) (-i \hat{p} + m \omega x)                 \\
                             & = \frac{1}{2 \hbar m \omega} [\hat{p}^2 + (m \omega x)^2 - i m \omega (x \hat{p} - \hat{p} x)].
        \end{align*} The extra term involving $x \hat{p} - \hat{p} x$ is called the \textbf{commutator} of $x$ and $\hat{p}$ — it's a measure of how badly they fail to commute.

  \item In general, the commutator of two operators $\hat{A}$ and $\hat{B}$ is \[[\hat{A}, \hat{B}] = \hat{A} \hat{B} - \hat{B} \hat{A}.\] It's often easier to calculate the commutator of two operators if you introduce a test function $f$, expand, and remove $f$ at the end.

  \item Using this notation, the product above can be rewritten \[\hat{a}_- \hat{a}_+ = \frac{1}{2 \hbar m \omega} [\hat{p}^2 + (m \omega x)^2] - \frac{i}{2 \hbar} [x, \hat{p}].\]

  \item It turns out that \[[x, \hat{p}] = i \hbar.\] This equation is called the \textbf{canonical commutation relation} and using it we find \[\hat{a}_- \hat{a}_+ = \frac{1}{\hbar \omega} \hat{H} + \frac{1}{2}\] or \[\hat{H} = \hbar \omega \left( \hat{a}_- \hat{a}_+ - \frac{1}{2} \right).\]

  \item Note that the order of the operators is important. Going through the same process for $\hat{a}_+ \hat{a}_-$ gives \[\hat{a}_+ \hat{a}_- = \frac{1}{\hbar \omega} \hat{H} - \frac{1}{2}\] and \[\hat{H} = \hbar \omega \left( \hat{a}_+ \hat{a}_- + \frac{1}{2} \right).\]

  \item If $\psi$ satisfies the Schrödinger equation with energy $E$, i.e. $\hat{H} \psi = E \psi$, then $\hat{a}_+ \psi$ satisfies it with energy $E + h \omega$ \[\hat{H} (\hat{a}_+ \psi) = (E + h \omega) \psi\] and $\hat{a}_- \psi$ satisfies it with energy $E - h \omega$ \[\hat{H} (\hat{a}_- \psi) = (E - h \omega) \psi.\]

  \item $\hat{a}_\pm$ are called \textbf{ladder operators} because, if we know one solution to the Schrödinger equation, they can be used to climb up and down the energy ladder.

  \item However, we can't apply the lowering operator $\hat{a}_-$ an infinite number of times — eventually we'll reach a state of zero energy. The ``lowest rung'' $\psi_0$ occurs when $\hat{a}_- \psi_0 = 0$. Solving this equation we find \[\psi_0(x) = \left( \frac{m \omega}{\pi \hbar} \right)^{1 / 4} e^{-\frac{m \omega}{2 \hbar} x^2}\] and \[E_0 = \frac{1}{2} \hbar \omega.\]

  \item From here we can apply the raising operator $\hat{a}_+$ to find higher energy states \[\psi_n(x) = \frac{1}{\sqrt{n!}} (\hat{a}_+)^n \psi_0 \text{ with } E_n = \left( n + \frac{1}{2} \right) \hbar \omega.\]

  \item In the case of the infinite square well, the stationary states of the harmonic oscillator are orthogonal \[\int_{-\infty}^\infty \psi_m^* \psi_n \,d x = \delta_{m n}.\]
\end{itemize}

\subsubsection{Analytic Method}

\begin{itemize}
  \item By introducing the term \[\xi = \sqrt{\frac{m \omega}{\hbar}} x\] the Schrödinger equation for the harmonic oscillator \[-\frac{\hbar^2}{2 m} \frac{d^2 \psi}{d x^2} + \frac{1}{2} m \omega^2 x^2 \psi = E \psi\] can be rewritten \[\frac{d^2 \psi}{d \xi^2} = (\xi^2 - K) \psi\] where \[K = \frac{2 E}{\hbar \omega}\] is the energy of the system in units of $\hbar \omega / 2$.

  \item For large $\xi$ this has the approximate solution \[\psi(\xi) = h(\xi) e^{-\xi^2 / 2}.\] Substituting this into the Schrödinger equation gives \[\frac{d^2 h}{d \xi^2} - 2 \xi \frac{d h}{d \xi} + (K - 1) h = 0.\] If we assume the solution $h(\xi)$ is a power series in $\xi$ we get \[\sum_{j = 0}^\infty [(j + 1) (j + 2) a_{j + 2} - 2 j a_j + (K - 1) a_j] \xi^j = 0.\] By the uniqueness of power series expansions, the coefficient of each power of $\xi$ must be $0$ in order for the series overall to equal $0$ \[(j + 1) (j + 2) a_{j + 2} - 2 j a_j + (K - 1) a_j = 0.\] This gives a recurrence relation \[a_{j + 1} = \frac{2 j + 1 - K}{(j + 1) (j + 2)} a_j\] that can be used to generate the even- and odd-numbered coefficients by starting with $a_0$ and $a_1$, respectively.

  \item However, not all choices of $a_j$ result in normalisable wavefunctions. In order for them to be valid, the power series must terminate — there must be some ``highest'' $j$ (call it $n$) such that $a_{n + 2} = 0$. This will truncate \textbf{either} the even series or the odd series. The other one must be zero from the start — $a_1 = 0$ if $n$ is even, $a_0 = 0$ if $n$ is odd.

  \item In general $h_n(\xi)$ will be a polynomial of degree $n$ in $\xi$, involving even powers only if $n$ is even, and odd powers only if it's odd. Apart from the overall factor $a_0$ or $a_1$ these are the \textbf{Hermite polynomials, $\boldsymbol{H_n(\xi)}$}.

  \item By convention the arbitrary multiplicative factor is chosen such that the coefficient of the highest power of $\xi$ is $2^n$. With this convention, the normalised stationary states for the harmonic oscillator are \[\psi_n = \left( \frac{m \omega}{\pi \hbar} \right)^{1 / 4} \frac{1}{\sqrt{2^n n!}} H_n(\xi) e^{-\xi^2 / 2}.\]
\end{itemize}

\end{document}